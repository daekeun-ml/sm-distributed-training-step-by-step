{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166a54e9-3f5c-4189-972e-762fbecbe6d1",
   "metadata": {},
   "source": [
    "# Lab 2: Step-by-step fine-tune BERT model on Local Environment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b080408-8679-4630-b292-7682d02a0b58",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "\n",
    "본 모듈에서는 허깅페이스(HF; Hugging Face) `transformers` 및 `datasets` 라이브러리를 사용하여 한국어 텍스트 감성 분류 파인 튜닝을 수행합니다. 허깅페이스 라이브러리로 모델을 훈련하는 방법은 https://huggingface.co/docs/transformers/training 을 참조하세요. 그리고 트랜스포머와 BERT에 대한 배경 지식이 필요하면 아래 링크도 같이 참조하세요.\n",
    "\n",
    "- 트랜스포머: https://housekdk.gitbook.io/ml/ml/nlp/transformer\n",
    "- BERT: https://housekdk.gitbook.io/ml/ml/nlp/bert\n",
    "\n",
    "_**Note: SageMaker Studio Lab, SageMaker Studio, SageMaker 노트북 인스턴스, 또는 여러분의 로컬 머신에서 이 데모를 실행할 수 있습니다. SageMaker Studio Lab을 사용하는 경우 GPU를 활성화하세요.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd2284-9fcf-47b1-92ce-71069c1c278e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_from_disk, load_dataset\n",
    "#import torch, torch_xla.core.xla_model as xm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"True\"\n",
    "        \n",
    "# compute metrics function for binary classification\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f|1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1155a-c216-4b55-a735-7216a852e733",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Dataset preparation and preprocessing\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "\n",
    "본 핸즈온에서 사용할 말뭉치 데이터셋은 네이버 영화 리뷰 감성 분류 데이터(https://github.com/e9t/nsmc/) 공개 데이터셋으로 15만 건의 훈련 데이터와 5만 건의 테스트 데이터로 구성되어 있습니다. 이 데이터셋은 한국어 자연어 처리 모델 벤치마킹에 자주 사용됩니다.\n",
    "\n",
    "본 모듈은 빠른 실습을 위해 200건의 데이터만 샘플링하여 훈련을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587b285-c7eb-466c-bb38-9cf6c5595842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "eval_dir = 'eval'\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['document'], padding='max_length', max_length=128, truncation=True)\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)#.to(device)\n",
    "\n",
    "if (os.path.exists(train_dir) and os.path.exists(train_dir)):\n",
    "    print('== Load dataset from disk')\n",
    "    train_dataset = load_from_disk(train_dir)\n",
    "    eval_dataset = load_from_disk(eval_dir)\n",
    "else:\n",
    "    print('== Preprocessing dataset from scratch')\n",
    "    train_dataset = load_dataset(\"nsmc\", split=\"train\")\n",
    "    eval_dataset = load_dataset(\"nsmc\", split=\"test\")\n",
    "\n",
    "    train_num_samples = 200\n",
    "    eval_num_samples = 100\n",
    "    train_dataset = train_dataset.shuffle(seed=42).select(range(train_num_samples))\n",
    "    eval_dataset = eval_dataset.shuffle(seed=42).select(range(eval_num_samples))\n",
    "\n",
    "    # tokenize dataset\n",
    "    train_dataset = train_dataset.map(tokenize, batched=True, remove_columns=['id', 'document'])\n",
    "    eval_dataset = eval_dataset.map(tokenize, batched=True, remove_columns=['id', 'document'])\n",
    "\n",
    "    # set format for pytorch\n",
    "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "    eval_dataset = eval_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bf44a-29aa-4e38-aeb6-e8f0f863ebcd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Training and Evaluation\n",
    "---\n",
    "\n",
    "### Option 1. Fine-tune with HF Transformers Trainer\n",
    "\n",
    "허깅페이스 라이브러리의 `Trainer`로 모델을 쉽고 빠르게 훈련할 수 있습니다. 이 API를 사용하면 분산 훈련에 대한 추가 코딩 없이 편리하게 분산 훈련이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ce032-7d87-45a9-8b12-464f4c701600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    output_dir=\"./results\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model= model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.with_format(\"torch\"),\n",
    "    eval_dataset=eval_dataset.with_format(\"torch\"),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "print(train_result)\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ccdbfe-0a0a-4970-939a-5f3f3afa387a",
   "metadata": {},
   "source": [
    "### Option 2. Fine-tune in PyTorch (from scratch)\n",
    "\n",
    "자체 훈련 코드 작성을 선호하거나 추가 로직이 필요한 경우, 기존 PyTorch의 방식대로 훈련 코드를 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb6914-3127-4eca-8051-74ba203b44ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d1987-622f-4275-8e06-56271d21e6b9",
   "metadata": {},
   "source": [
    "훈련 및 검증 데이터의 미니배치 순회를 위한 DataLoader를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe36d14-cba1-4685-8a9e-4aa15acdb793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c3d7e-3923-426e-a53a-dac0de91a697",
   "metadata": {},
   "source": [
    "에포크와 DataLoader를 순회하면서 훈련을 수행합니다. 자세한 내용은 https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html 를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec98761-0cc1-4694-b480-1b080efb2bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_pbar = tqdm(total=len(train_loader), colour=\"blue\", leave=True, desc=f\"Training epoch {epoch}\")    \n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_pbar.update(1)\n",
    "        \n",
    "    train_pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826d556-b60a-4330-9b00-d0aa2d780115",
   "metadata": {},
   "source": [
    "`add_batch`를 사용하여 모든 배치를 누적하고 마지막에 지표를 계산합니다. 허깅페이스의 `evaluate` 라이브러리를 활용하면 추가 코딩 없이 편리하게 널리 활용되는 지표들이 사용 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774d052-b10b-4a9d-adbb-3e862c7440ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "preds_batch = torch.empty([0]).to(device)\n",
    "truths_batch = torch.empty([0]).to(device)\n",
    "metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "model.eval()\n",
    "eval_pbar = tqdm(total=len(eval_loader), colour=\"green\", leave=True, desc=f\"Evaluation\")     \n",
    "\n",
    "for batch in eval_loader:   \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    preds_batch = torch.cat([preds_batch, preds], dim=0)\n",
    "    truths_batch = torch.cat([truths_batch, batch['labels']], dim=0)\n",
    "    metrics.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "    eval_pbar.update(1)\n",
    "\n",
    "metrics.compute()\n",
    "eval_pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416f3e9-7e6e-4015-80a2-9076ecb5bea7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Visualization\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982148d-44cd-45db-9726-bfe429bf136c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, labels=True, title='Confusion matrix'):\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if labels:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b556767-01e3-49c1-8fca-7620cc5ffc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## If you want to use HF Library\n",
    "# eval_results = trainer.predict(eval_dataset)\n",
    "# y_true = eval_results.label_ids\n",
    "# y_pred = np.argmax(eval_results.predictions, axis=1)\n",
    "\n",
    "y_true = truths_batch.cpu().numpy()\n",
    "y_pred = preds_batch.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108fe84-c0ec-4ac4-8453-faaa4ed2669d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cf, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
