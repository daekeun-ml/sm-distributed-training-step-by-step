{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efcfe57-9a0c-449f-ae8c-99ff3adf3d9c",
   "metadata": {},
   "source": [
    "# Lab 3: Intro to Distributed Training (Data Parallel)\n",
    "---\n",
    "\n",
    "PyTorch 데이터 병렬화에 익숙하신 분들은 이 노트북 섹션을 건더뛰고 다음 섹션으로 진행하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38faba-dfd0-400b-9bcf-8466fa38588d",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 1. PyTorch Training Script for Single GPU\n",
    "---\n",
    "앞 모듈의 주피터 노트북 코드를 단일 파이썬 스크립트로 작성한 결과입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7da54-0ead-46c2-a78c-867f8a86f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize scripts/train_single.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d2a87-6143-43eb-8bb7-e15850032437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "TRAIN_SINGLE_GPU_CMD = f\"\"\"cd scripts && python train_single.py --num_epochs 1 \\\n",
    "    --train_batch_size 32 \\\n",
    "    --eval_batch_size 64 \\\n",
    "    --use_fp16 True\n",
    "\"\"\"\n",
    "\n",
    "print(f'Running command: \\n{TRAIN_SINGLE_GPU_CMD}')\n",
    "! {TRAIN_SINGLE_GPU_CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d0c17-7403-425d-98db-3f9f69e94b14",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. PyTorch Distributed Data Parallel Tutorial\n",
    "---\n",
    "\n",
    "분산 훈련을 위해 상기 스크립트에서 몇 줄의 변환이 필요합니다. 차근차근 알아보도룍 하죠.\n",
    "\n",
    "#### 기본 용어\n",
    "\n",
    "- **rank**: 글로벌 프로세스 id (각 GPU는 단일 프로세스에 매칭됩니다)\n",
    "- **local_rank**: 해당 노드에서의 프로세스 id (a unique local ID for processes running in a single node)\n",
    "- **node_size**: 독립된 노드의 개수\n",
    "- **num_gpu**: 각 노드에서 사용할 GPU 개수\n",
    "- **world_size**: 총 글로벌 프로세스 개수 (node_size * num_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc19d9-99eb-4d15-a298-c1b0e2edcc7f",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1. Setup the process group\n",
    "\n",
    "각 프로세스당 GPU를 할당하기 위한 초기화를 수행합니다. 이를 통해 여러 노드에 있는 여러 프로세스가 동기화되고 통신합니다.\n",
    "\n",
    "```python\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "def setup():\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    \n",
    "    if 'WORLD_SIZE' in os.environ:\n",
    "        # Environment variables set by torch.distributed.launch or torchrun\n",
    "        world_size = int(os.environ['WORLD_SIZE'])\n",
    "        rank = int(os.environ['RANK'])\n",
    "        local_rank = int(os.environ['LOCAL_RANK'])\n",
    "    elif 'OMPI_COMM_WORLD_SIZE' in os.environ:\n",
    "        # Environment variables set by mpirun \n",
    "        world_size = int(os.environ['OMPI_COMM_WORLD_SIZE'])\n",
    "        rank = int(os.environ['OMPI_COMM_WORLD_RANK'])\n",
    "        local_rank = int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])\n",
    "    else:\n",
    "        sys.exit(\"Can't find the evironment variables for local rank\")\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376d1e7-8625-4037-b9fb-ce5564be77e3",
   "metadata": {},
   "source": [
    "### 2.2. Split the DataLoader to each process\n",
    "\n",
    "`DataLoader`를 DistributedSampler로 각 프로세스로 분배하고, 각 프로세스당 미니배치가 겹치지 않게 합니다. `DistributedSampler`를 사용하면 전체 데이터를 GPU의 개수로 나눈 부분 데이터셋에서만 데이터를 샘플링합니다. 이 때 주의할 점은 `DistributedSampler`를 사용하면 `DataLoader` 호출 시 `shuffle=False`로 설정해야 합니다!\n",
    "\n",
    "#### [As-is] Single GPU\n",
    "\n",
    "```python\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=args.train_batch_size, \n",
    "    num_workers=4, shuffle=True\n",
    ")    \n",
    "eval_loader = DataLoader(\n",
    "    dataset=eval_dataset, batch_size=args.eval_batch_size, \n",
    "    num_workers=4, shuffle=False\n",
    ")\n",
    "```\n",
    "\n",
    "#### [To-be] Distributed Training\n",
    "\n",
    "```python\n",
    "train_sampler = DistributedSampler(train_dataset, num_replicas=args.world_size, rank=args.rank)\n",
    "eval_sampler = DistributedSampler(eval_dataset, num_replicas=args.world_size, rank=args.rank)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, \n",
    "    num_workers=4*torch.cuda.device_count(), shuffle=False\n",
    ")    \n",
    "eval_loader = DataLoader(\n",
    "    dataset=eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, \n",
    "    num_workers=4*torch.cuda.device_count(), shuffle=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7bab1-4f8a-493d-a106-9e42f48470d7",
   "metadata": {},
   "source": [
    "### 2.3. Wrap model to DDP\n",
    "\n",
    "기존 모델을 DDP()로 래핑합니다. 이는 한 줄의 코드로 간단히 수행 가능합니다.\n",
    "\n",
    "#### [As-is] Single GPU\n",
    "\n",
    "```python\n",
    "model = BertForSequenceClassification.from_pretrained(args.model_id, num_labels=2).to(device)\n",
    "\n",
    "```\n",
    "\n",
    "#### [To-be] Distributed Training\n",
    " \n",
    "```python\n",
    "model = BertForSequenceClassification.from_pretrained(args.model_id, num_labels=2).to(device)\n",
    "model = DDP(model, device_ids=[device])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95efd462-e29e-411f-abea-041ed213e9bb",
   "metadata": {},
   "source": [
    "### 2.4.  set_epoch()\n",
    "\n",
    "데이터 병렬화 과정에서 각 에폭 시작 시 `set_epoch()` 메서드를 호출해야 미니배치 셔플링이 제대로 작동합니다. 이를 수행하지 않으면 항상 동일한 셔플링이 사용되어 훈련 효과가 떨어집니다.\n",
    "\n",
    "#### [As-is] Single GPU\n",
    "\n",
    "```python\n",
    "for epoch in range(1, args.num_epochs+1):\n",
    "    ...\n",
    "```\n",
    "\n",
    "#### [To-be] Distributed Training\n",
    " \n",
    "```python\n",
    "for epoch in range(1, args.num_epochs+1):\n",
    "    train_sampler.set_epoch(epoch)\n",
    "    eval_sampler.set_epoch(epoch)\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489ca8c-38b5-478e-9116-78fa4a5b54f0",
   "metadata": {},
   "source": [
    "### 2.5. Destroy Process group\n",
    "분산 훈련을 완료하였으면 프로세스 그룹을 종료합니다.\n",
    "\n",
    "#### [As-is] Single GPU\n",
    "\n",
    "```python\n",
    "...\n",
    "main(args) # main logic\n",
    "```  \n",
    "\n",
    "#### [To-be] Distributed Training\n",
    "\n",
    "```python\n",
    "...\n",
    "main(args) # main logic\n",
    "dist.destroy_process_group()\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c293d-f2c3-4979-bdd0-8b02945b022b",
   "metadata": {},
   "source": [
    "### (Optional) 2.6. AMP (Automatic Mixed Precision)\n",
    "\n",
    "모델이 거대해지면서 한정된 GPU 메모리에 모델을 모두 올리기 어렵고 미니배치 크기 또한 키울 수 없는 상황들이 종종 있습니다. 이를 위해 Gradient Checkpointing, 지식 증류, 모델 병렬화 등의 기법을 사용할 수도 있지만, 디폴트로 사용되는 32비트 연산(FP32) 대신 16비트 연산을 사용(FP16)해서 메모리를 절약하고 훈련 속도를 높일 수도 있습니다. PyTorch 구 버전에서는 이를 사용하기 위해서는 별도로 NVIDI의 Apex 라이브러리(https://github.com/NVIDIA/apex)를 설치해야 했지만, PyTorch 1.5.0 버전부터는 AMP 모듈이 기본으로 추가되어 있기에 몇 줄의 코드만으로 쉽게 FP16을 적용할 수 있습니다.\n",
    "\n",
    "\n",
    "#### Autocasting and Gradient Scaling\n",
    "특정 연산에 대한 forward 패스가 FP16 입력이 있는 경우, 해당 연산에 대한 backward pass는 FP16 그래디언트(gradient)를 생성하는데, 이 때 크기가 작은 그래디언크 값은 FP16으로 전부 표현할 수 없기에 0으로 세팅되는 언더플로우 현상이 발생합니다. \n",
    "\n",
    "![amp1](imgs/amp1.png)\n",
    "(출처: https://arxiv.org/pdf/1710.03740.pdf)\n",
    "\n",
    "이 때 loss에 scale factor를 곱하여 scaling된 손실에 backward pass를 호출하면 그래디언트의 크기가 매우 커지므로 FP16이 표현할 수 있는 범위에 들어옵니다. 이를 psuedo 코드로 표현하면 다음과 같습니다.\n",
    "``` \n",
    "scaled_loss = loss * scale_factor\n",
    "``` \n",
    "하지만 backward pass 호출 후 기존 weight를 업데이트할 때는 원래의 스케일로 unscaling을 수행해야겠죠? 이를 몇 줄의 코드로 간단히 적용할 수 있습니다.\n",
    "\n",
    "좀 더 구체적인 AMP 최적화 옵션은 아래 내용을 참조하세요.\n",
    "![amp2](imgs/amp2.png)\n",
    "\n",
    "- **copt_level**c\n",
    "    - O0: FP32 training\n",
    "    - O1: [Default] TensorCore을 이용한 FP32 / FP16 혼합 연산으로 TensorCore에 적합한 연산(ops)들은 FP16으로 캐스팅하고 정확한 계산이 필요한 연산들은 FP32를 유지\n",
    "    - O2: Almost FP16 (BatchNorm weight를 제외한 Model weight가 FP16으로 캐스팅)\n",
    "    - O3: FP16 training\n",
    "- **cast_model_type**: 모델 파라메터를 어떤 타입으로 변환할 것인지 여부\n",
    "- **patch_torch_functions**: 함수를 TensorCore용으로 변환할지 여부\n",
    "- **keep_batchnorm_fp32**: BatchNorm 연산을 FP32로 유지할지 여부\n",
    "- **master_weights**: 연산 시의 weight를 FP32로 할지 여부\n",
    "- **loss_scale**: Gradient Scaling 관련 파라메터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08d0be-ae16-47a3-b9d6-8d739a206f80",
   "metadata": {},
   "source": [
    "#### [As-is] FP32\n",
    "\n",
    "```python\n",
    "def train_model(args, device, model, train_loader, eval_loader, optimizer, lr_scheduler, epoch, pbar):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss          \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "```        \n",
    "\n",
    "#### [As-is] AMP Enabled\n",
    "\n",
    "```python\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_model(args, device, model, train_loader, eval_loader, optimizer, lr_scheduler, epoch, pbar):\n",
    "    model.train()\n",
    "\n",
    "    # AMP (Create gradient scaler)\n",
    "    scaler = GradScaler(init_scale=16384)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=args.use_fp16):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "                \n",
    "        if args.use_fp16:\n",
    "            # Backpropagation w/ gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6446d14-578e-49f5-9d56-482df2aaf23f",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 3. PyTorch Training Script for Distributed Training\n",
    "---\n",
    "위 지침대로 코드를 변경한 최종 스크립트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7d10d-08b7-4e3f-aa53-e123a9f3c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize scripts/train_pytorchddp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c55b17-1505-48fb-a6f0-e6a5b8b813b6",
   "metadata": {},
   "source": [
    "`torchrun`으로 분산 훈련 스크립트를 실행합니다. `mpirun`, `torch.multiprocessing.spawn()`, `torch.distributed.launch()` 등의 다양한 방법으로 실행하지만, PyTorch 최신 버전은 `torchrun`으로 분산 훈련을 수행하는 것을 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24640fa4-2ec2-4541-bf3b-cfa0664a2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "TRAIN_DDP_CMD = f\"\"\"cd scripts && torchrun --nnodes=1 --nproc_per_node={n_gpus} train_pytorchddp.py \\\n",
    "    --train_batch_size 32 \\\n",
    "    --eval_batch_size 64 \\\n",
    "    --use_fp16 True\n",
    "\"\"\"\n",
    "\n",
    "print(f'Running command: \\n{TRAIN_DDP_CMD}')\n",
    "! {TRAIN_DDP_CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c74526-8b1c-4b08-8ad4-973860a8074d",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 4. SagageMaker Distributed Data Parallel\n",
    "---\n",
    "기존 PyTorch DDP 코드에서 거의 변경할 부분이 없습니다. SageMaker 데이터 병렬화 라이브러리를 임포트하고 프로세스 그룹 초기화 시 백엔드를 nccl에서 smddp로 변경하면 됩니다. 다만, 기존 개발 환경에서처럼 곧바로 훈련을 수행할 수 없기에 최소한 로컬 모드를 사용해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41306ef4-cf41-4229-b4ff-c47df39570ba",
   "metadata": {},
   "source": [
    "#### [As-is] PyTorch DDP\n",
    "\n",
    "```python\n",
    "...\n",
    "dist.init_process_group(backend=\"nccl\")\n",
    "```  \n",
    "\n",
    "#### [To-be] SageMaker DDP\n",
    "\n",
    "```python\n",
    "...\n",
    "import smdistributed.dataparallel.torch.torch_smddp\n",
    "...\n",
    "dist.init_process_group(backend=\"smddp\")\n",
    "```   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
